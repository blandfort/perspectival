{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7eb9fc-c5bf-436f-ad25-746ba8072741",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4fc2fe-1d50-4003-8dbd-ff0859de7c6e",
   "metadata": {},
   "source": [
    "# HellaSwag Example\n",
    "\n",
    "In this example, we are comparing two models on the HellaSwag dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3f9ad-1fbb-4733-8858-8a2e40a2ae4e",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e77af4-47fb-49a6-a429-43f15f34044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perspectival.model import Transformer\n",
    "\n",
    "model = Transformer('apple/OpenELM-270M', trust_remote_code=True)\n",
    "model2 = Transformer('apple/OpenELM-270M-Instruct', trust_remote_code=True)\n",
    "\n",
    "# Note: You can also use LazyTransformer if you prefer to only load the models\n",
    "# during steps where they are used for computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05cdd9b-b35d-4391-8328-ea36bb8502d3",
   "metadata": {},
   "source": [
    "## Set up an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "668629c7-a5dd-40e9-8680-3f3bf39b2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/code/perspectives/venv/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from perspectival.loader import load_hellaswag\n",
    "from perspectival.experiment import Experiment\n",
    "\n",
    "dataset, features = load_hellaswag()\n",
    "experiment = Experiment(dataset=dataset, name='HellaSwag Example', features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67786e4-7ab6-4cb4-87e2-902ad05b789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Select a random subset of the dataset for quicker processing\n",
    "experiment = experiment.sample(num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad66be-535c-4fff-9b4e-045100a99069",
   "metadata": {},
   "source": [
    "## Computing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b506237c-8107-40f3-8b4e-97187cd00cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "experiment.compute_correctness(models=[model, model2])\n",
    "experiment.compute_disagreement(models=[model, model2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa42f89-ddd2-469c-ae88-b08d7c9a58be",
   "metadata": {},
   "source": [
    "## Exploring Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd1375e-9156-4b77-8b94-00dcb716a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall disagreement rate: 0.15\n",
      "\n",
      "apple/OpenELM-270M\n",
      "- Accuracy: 0.45\n",
      "- Output: [(1, 30), (3, 28), (0, 25), (2, 17)]\n",
      "apple/OpenELM-270M-Instruct\n",
      "- Accuracy: 0.54\n",
      "- Output: [(1, 29), (3, 28), (0, 25), (2, 18)]\n"
     ]
    }
   ],
   "source": [
    "# Some general output statistics\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "scores = experiment.get_feature('LogDisagreement', models=(model.name, model2.name)).values\n",
    "disagreement_rate = sum(scores>0)/len(scores)\n",
    "print(f\"Overall disagreement rate: {disagreement_rate:.2f}\\n\")\n",
    "\n",
    "for m in [model, model2]:\n",
    "    print(m.name)\n",
    "    accuracy = np.mean(experiment.get_feature('PredictionCorrectness', model=m.name).values)\n",
    "    print(f\"- Accuracy: {accuracy:.2f}\")\n",
    "    print(\"- Output:\", Counter(experiment.get_feature('ModelChoices', model=m.name).values).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94dca7a4-3285-4b23-a9a5-8add230086a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEM (train_30757)\n",
      "\"\"\"[header] How to make honey orange glazed chicken [title] Preheat the oven to 375f (190c, gas mark 5) before you begin the rest of the preparations. [title] Coat a baking dish with a very thin layer of extra virgin olive oil. [title] Place breasts or chicken in the baking dish.\"\"\"\n",
      "Options: ['[step] Cover with pan and cook uncovered until the chicken turns a light golden colour. [title] Remove and reserve the cooked chicken for garnish.', '[step] Arrange chicken breasts or chicken with skin between them on a baking dish. [title] Place carrots or squash in the bottom of each pan.', '[step] Turn both pieces of chicken inside out. [title] Score each breast in an upward motion into 5 small to 1 inch (2.5 to 3.8 cm) thick slices of chicken.', '[title] Splash with liquid smoke to cover chicken lightly, then rub on some more olive oil. [title] Grind peppercorn medley and sea salt lightly over the chicken.']\n",
      "\n",
      "FEATURES\n",
      "GroundTruth 3\n",
      "OptionLogLikelihood apple/OpenELM-270M [-110.24429 -103.38159 -113.47709 -111.03627]\n",
      "OptionLogLikelihood apple/OpenELM-270M-Instruct [-139.27902 -137.1414  -132.91243 -122.71856]\n",
      "ModelChoices apple/OpenELM-270M 1\n",
      "ModelChoices apple/OpenELM-270M-Instruct 3\n",
      "PredictionCorrectness apple/OpenELM-270M 0.0\n",
      "PredictionCorrectness apple/OpenELM-270M-Instruct 1.0\n",
      "LogDisagreement ('apple/OpenELM-270M', 'apple/OpenELM-270M-Instruct') 110.40223\n",
      "BinaryDisagreement ('apple/OpenELM-270M', 'apple/OpenELM-270M-Instruct') True\n",
      "\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "ITEM (train_20243)\n",
      "\"\"\"[header] How to be familiar with various types of mechanisms of organic reactions [title] Organic reactions can usually proceed in one of two ways. [step] One of them is concerted reaction that takes place in one step with one transition state. The other type of reactions in organic chemistry is the non-concerted type of reactions.\"\"\"\n",
      "Options: ['The latter type is the dominant type of most chemical reactions. Non-concerted organic reactions usually have intermediate structures that are highly reactive carbon species.', '[substeps] Recognizing how organic reactions can usually progress in one simple process will make it easier to see a pattern of how they might be managed. While it can be hard to differentiate these right ways, focusing on what organic reactions are going to happen will get you in the habit of listening to the environment.', '[substeps] Produce magnets come in all shapes and sizes when produced in a particular form. For example, special objects such as a potato can be generated with organic materials such as cotton, felt, or crepe.', 'One way is creating a new reaction with differing directions, but there are important differences between the two reactions. [substeps] In the non-concerted type, the side reaction taking place is composed of three different reactions.']\n",
      "\n",
      "FEATURES\n",
      "GroundTruth 0\n",
      "OptionLogLikelihood apple/OpenELM-270M [-167.59445 -204.06624 -202.1969  -160.08795]\n",
      "OptionLogLikelihood apple/OpenELM-270M-Instruct [-183.595   -242.82959 -253.60703 -195.90807]\n",
      "ModelChoices apple/OpenELM-270M 3\n",
      "ModelChoices apple/OpenELM-270M-Instruct 0\n",
      "PredictionCorrectness apple/OpenELM-270M 0.0\n",
      "PredictionCorrectness apple/OpenELM-270M-Instruct 1.0\n",
      "LogDisagreement ('apple/OpenELM-270M', 'apple/OpenELM-270M-Instruct') 92.428024\n",
      "BinaryDisagreement ('apple/OpenELM-270M', 'apple/OpenELM-270M-Instruct') True\n",
      "\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show items with max disagreement\n",
    "scores = experiment.get_feature('LogDisagreement', models=(model.name, model2.name)).values\n",
    "samples = experiment.sample(num=2, sampling_method='last', ordering_scores=scores)\n",
    "samples.display_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb75ce-ca4f-4629-8a07-7675fd7c92b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
